{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff5793ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.gpt2.modeling_gpt2 import GPT2Model\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from einops import rearrange\n",
    "from transformers.models.gpt2.configuration_gpt2 import GPT2Config\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d8dd199",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2 = GPT2Model.from_pretrained('gpt2', output_attentions=True, output_hidden_states=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e604e97c",
   "metadata": {},
   "source": [
    "### Short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca683666",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'NP'\n",
    "exogenous_variables = ['Grid Load','Wind Power']\n",
    "endogenous_variable = 'Nord Pool Electricity Price'\n",
    "data_collection = 'Nord Pool electricity market'\n",
    "\n",
    "data_name = 'PJM'\n",
    "exogenous_variables = ['System Load','SyZonal COMED load'] \n",
    "endogenous_variable = 'Pennsylvania-New Jersey-Maryland Electricity Price'\n",
    "data_collection = 'Pennsylvania-New Jersey-Maryland market'\n",
    "\n",
    "data_name = 'BE'\n",
    "exogenous_variables = ['Generation','System Load'] \n",
    "endogenous_variable = 'Belgium\\'s Electricity Price'\n",
    "data_collection = 'Belgium\\'s electricity market'\n",
    "\n",
    "data_name = 'FR'\n",
    "exogenous_variables = ['Generation','System Load'] \n",
    "endogenous_variable = 'France\\'s Electricity Price'\n",
    "data_collection = 'France\\'s electricity market'\n",
    "\n",
    "data_name = 'DE'\n",
    "exogenous_variables = ['Wind power','Ampirion zonal load'] \n",
    "endogenous_variable = 'German\\'s Electricity Price'\n",
    "data_collection = 'German\\'s electricity market'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a44b25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "exogenous_variables_text_template = 'This exogenous variable is'\n",
    "endogenous_template = 'The endogenous variable is'\n",
    "dataset_template1 = f'This dataset is {data_name}, containing the data collected from {data_collection}. Exogenous variables are'\n",
    "dataset_template2 = f'and it is necessary to utilize these external variables sequentially to predict the endogenous variable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2eb71f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This exogenous variable is Wind power.', 'This exogenous variable is Ampirion zonal load.', \"The endogenous variable is German's Electricity Price.\", \"This dataset is DE, containing the data collected from German's electricity market. Exogenous variables are Wind power, Ampirion zonal load,and it is necessary to utilize these external variables sequentially to predict the endogenous variable German's Electricity Price.\"]\n"
     ]
    }
   ],
   "source": [
    "prompts = []\n",
    "for v in exogenous_variables:\n",
    "    #v = variables[i]\n",
    "    prompts.append(exogenous_variables_text_template+' '+ v+'.')\n",
    "    dataset_template1 = dataset_template1+' '+v+','\n",
    "prompts.append(endogenous_template+' '+ endogenous_variable+'.')\n",
    "dataset_template2 = dataset_template2 + ' ' +  endogenous_variable+ '.'\n",
    "dataset_template1 = dataset_template1 + dataset_template2\n",
    "prompts.append(dataset_template1)\n",
    "print(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "858e21ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 768])\n",
      "torch.Size([1, 12, 768])\n",
      "torch.Size([1, 9, 768])\n",
      "torch.Size([1, 50, 768])\n",
      "torch.Size([4, 768])\n"
     ]
    }
   ],
   "source": [
    "text_emds = []\n",
    "for p in prompts:\n",
    "    tokens = tokenizer(p, padding=False, truncation=True, return_tensors=\"pt\")\n",
    "    # 2. 使用tokenizer将文本转换为模型的输入表示\n",
    "    input_ids = tokens[\"input_ids\"]\n",
    "    # 3. 将输入表示传递给您的GPT-2模型，获取文本的嵌入表示\n",
    "    with torch.no_grad():\n",
    "        outputs = gpt2(input_ids=input_ids)\n",
    "    print(outputs.last_hidden_state.shape)\n",
    "    text_emds.append(outputs.last_hidden_state[:,-1])\n",
    "#text_emds.insert(0, text_emds[-1])\n",
    "text_emds = torch.cat(text_emds,dim=0)\n",
    "print(text_emds.shape)\n",
    "torch.save(text_emds, data_name+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aa8918",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
